{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sigmoid\n",
    "def sigmoid(Z):\n",
    "    \n",
    "    A = 1.0/(1.0 + np.exp(-Z))  # Activation\n",
    "    C = Z                       # Cache\n",
    "    \n",
    "    return A , C \n",
    "\n",
    "\n",
    "def sigmoid_prime(dA, C): ## Derivative and Cache\n",
    "    \n",
    "    Z = C                 ## Cache\n",
    "    \n",
    "    S, _  = sigmoid(dA)\n",
    "    ds = S * (1-S)\n",
    "    \n",
    "    dZ = dA * S\n",
    "    \n",
    "    return dZ\n",
    "\n",
    "\n",
    "### RELU\n",
    "def relu(Z, alpha=0.00001):\n",
    "    C = Z                       # Cache\n",
    "    A = np.maximum(alpha,Z)     # Activation\n",
    "    \n",
    "    return A , C \n",
    "\n",
    "\n",
    "def relu_prime(dA, C):\n",
    "    \n",
    "    Z = C                      ## Cache\n",
    "    \n",
    "    dZ = np.array(dA, copy=True)\n",
    "    \n",
    "    dZ[Z <= 0] = 0\n",
    "    dZ[Z >  0] = 1\n",
    "    \n",
    "    return dZ\n",
    "\n",
    "\n",
    "### tanH\n",
    "def tanh(Z):\n",
    "    \n",
    "    C = Z                       # Cache\n",
    "    A = np.tanh(Z)              # Activation\n",
    "    \n",
    "    return A , C\n",
    "\n",
    "\n",
    "def tanh_prime(dA, C):\n",
    "    \n",
    "    Z = C                      ## Cache\n",
    "    \n",
    "    dZ = 1-np.tanh(dA)**2\n",
    "    \n",
    "    return dZ\n",
    "\n",
    "### Identity\n",
    "def identity(Z):\n",
    "    \n",
    "    C = Z                       # Cache\n",
    "    A = Z                       # Activation\n",
    "    \n",
    "    return A , C\n",
    "\n",
    "\n",
    "def identity_prime(dA, C):\n",
    "    \n",
    "    Z = C                      ## Cache\n",
    "    \n",
    "    dZ = dA\n",
    "    \n",
    "    return dZ\n",
    "\n",
    "\n",
    "### SoftMax\n",
    "def softmax(Z, axis=1):\n",
    "    \n",
    "    C = Z\n",
    "    A = np.exp(x) / np.sum(np.exp(x), axis = axis, keepdims = True)\n",
    "    \n",
    "    return A , C\n",
    "\n",
    "def softmax_prime(dA, C):\n",
    "    \n",
    "    Z = C                      ## Cache\n",
    "    \n",
    "    s = dA.reshape(-1,1)\n",
    "    dZ = p.diagflat(s) - np.dot(s, s.T)\n",
    "    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loss L1\n",
    "def L1(yhat, y):\n",
    "    \n",
    "    loss = np.sum(abs(y-yhat))\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "### Loss L2\n",
    "def L2(yhat, y):\n",
    "    \n",
    "    loss = np.dot( (y-yhat),(y-yhat) )\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "### Loss Mean Square Error\n",
    "def mse(yhat, y):\n",
    "    \n",
    "    loss = np.mean(np.power(y-yhat, 2))\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "def mse_prime(yhat, y):\n",
    "    \n",
    "    loss_prime = (2 * (y-yhat)) /y.size\n",
    "    \n",
    "    return loss_prime\n",
    "\n",
    "\n",
    "### Loss cross entopy cost\n",
    "def cross_entropy_cost(yhat, y):\n",
    "    \n",
    "    m = y.shape[1]\n",
    "    \n",
    "    cost = np.squeeze( (1./m) * (-np.dot(y,np.log(yhat).T) - np.dot(1-y, np.log(1-yhat).T)) )\n",
    "    \n",
    "    return cost\n",
    "\n",
    "### Loss cross entopy cost\n",
    "def cross_entropy_cost_prime(yhat, y):\n",
    "    \n",
    "    dA = - (np.divide(y, yhat) - np.divide(1 - y, 1 - yhat))\n",
    "    \n",
    "    return dA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_map = {\n",
    "        'Identity':(identity,identity_prime),\n",
    "        'Sigmoid' :(sigmoid ,sigmoid_prime ),\n",
    "        'Relu'    :(relu    ,relu_prime    ),\n",
    "        'Tanh'    :(tanh    ,tanh_prime    ),\n",
    "        'Softmax' :(softmax ,softmax_prime )\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_Unit:\n",
    "    def __init__(self, activation_fn='Identity'):\n",
    "        \n",
    "        self.n_X = None  # Input_size\n",
    "        \n",
    "        self.activation_f = activation_map[activation_fn][0]\n",
    "        self.activation_b = activation_map[activation_fn][1]\n",
    "        \n",
    "    def forward(self, X):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def backward(self, dA, cache):\n",
    "        raise NotImplementedError\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nn_unit import NN_Unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnectedUnit(NN_Unit):\n",
    "    \n",
    "    def __init__(self, n_X, n_A, activation_fn): # num Input , num_output\n",
    "        super(FullyConnectedUnit, self).__init__(activation_fn)\n",
    "        \n",
    "        self.n_X = n_X\n",
    "        \n",
    "        self.W = np.random.rand(n_A, n_X) * 0.001\n",
    "        self.B = np.zeros((n_A, 1))\n",
    "                \n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "        \n",
    "        self.Z = self.W.dot(self.X) + self.B\n",
    "        \n",
    "        Z_cache = (self.X, self.W, self.B)\n",
    "        \n",
    "        self.A, A_cache = self.activation_f(self.Z)\n",
    "        \n",
    "        return self.A, (Z_cache, A_cache)\n",
    "\n",
    "    def backward(self, dA, cache):\n",
    "        \n",
    "        Z_cache, A_cache = cache\n",
    "        A , W , B = Z_cache        \n",
    "        \n",
    "        dZ = self.activation_b(dA, A_cache)\n",
    "        \n",
    "        m = A.shape[1]\n",
    "        \n",
    "        dW = 1./m * np.dot(dZ,A.T)\n",
    "        dB = 1./m * np.sum(dZ, axis = 1, keepdims = True)\n",
    "        dA = np.dot(W.T,dZ)\n",
    "        \n",
    "        return dA, dW, dB\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_Layer:\n",
    "    def __init__(self):\n",
    "        self.nn_unit = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def backward(self, dA, cache):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def update(self, grads, lr=0.001):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from layer import NN_Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnectedLayer(NN_Layer):\n",
    "    \n",
    "    def __init__(self, num_in, num_out, activation_fn): # num Input , num_output\n",
    "        \n",
    "        self.ins = num_in\n",
    "        self.outs = num_out\n",
    "        self.nn_unit = FullyConnectedUnit(num_in,num_out,activation_fn)\n",
    "                \n",
    "    def forward(self, X):\n",
    "        \n",
    "        self.A, (Z_cache, A_cache) = self.nn_unit.forward(X)\n",
    "        \n",
    "        return self.A, (Z_cache, A_cache)\n",
    "\n",
    "    def backward(self, dA, cache):\n",
    "        \n",
    "        dA, dW, dB = self.nn_unit.backward(dA, cache)\n",
    "        \n",
    "        return dA, dW, dB\n",
    "    \n",
    "    def update(self, grads, lr=0.0075):\n",
    "        self.nn_unit.W = self.nn_unit.W - (lr * grads[1])\n",
    "        self.nn_unit.B = self.nn_unit.B - (lr * grads[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_Network:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "        self.outs   = []\n",
    "        self.caches = []\n",
    "        self.grads  = []\n",
    "    \n",
    "    def add_layer(self, layer):\n",
    "        num_out, num_in = layer.outs, layer.ins\n",
    "        self.layers.append(layer)\n",
    "        self.outs.append(np.zeros((num_out, 1)))\n",
    "        self.caches.append( (0,0) )\n",
    "        self.grads.append( (0,0,0) )\n",
    "        \n",
    "    def train(self, X, Y, epochs= 100):\n",
    "        for e in range(0,epochs):\n",
    "            A = X\n",
    "            for idx, l in enumerate(self.layers):\n",
    "                A, cache = l.forward(A)\n",
    "                self.outs[idx] = A\n",
    "                self.caches[idx] = cache            \n",
    "\n",
    "            cost = cross_entropy_cost(A, Y)\n",
    "            dA = cross_entropy_cost_prime(A, Y)\n",
    "            \n",
    "            cnt = len(self.layers)\n",
    "            for i in reversed(range(0, cnt)):\n",
    "                dA, dW, dB = self.layers[i].backward(dA, self.caches[i])\n",
    "                self.grads[i] = (dA,dW,dB)\n",
    "\n",
    "            for i in range(0, cnt):\n",
    "                self.layers[i].update(self.grads[i])            \n",
    "            \n",
    "            if e%100 == 0 and e != 0:\n",
    "                print(f\"Cost at epoch {e} is {cost}\")\n",
    "        \n",
    "    def predict(self, X, Y):\n",
    "        A = X\n",
    "        for idx, l in enumerate(self.layers):\n",
    "            A, cache = l.forward(A)\n",
    "        print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    train_dataset = h5py.File('datasets/train_catvnoncat.h5', \"r\")\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "    test_dataset = h5py.File('datasets/test_catvnoncat.h5', \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
    "    \n",
    "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "    \n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "train_x_orig, train_y, test_x_orig, test_y, classes = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x's shape: (12288, 209)\n",
      "test_x's shape: (12288, 50)\n"
     ]
    }
   ],
   "source": [
    "train_x_flatten = train_x_orig.reshape(train_x_orig.shape[0], -1).T   # The \"-1\" makes reshape flatten the remaining dimensions\n",
    "test_x_flatten = test_x_orig.reshape(test_x_orig.shape[0], -1).T\n",
    "\n",
    "# Standardize data to have feature values between 0 and 1.\n",
    "train_x = train_x_flatten/255.\n",
    "test_x = test_x_flatten/255.\n",
    "\n",
    "print (\"train_x's shape: \" + str(train_x.shape))\n",
    "print (\"test_x's shape: \" + str(test_x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc1 = FullyConnectedLayer(12288,100,'Relu')\n",
    "fc2 = FullyConnectedLayer(100,1,'Sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN_Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add_layer(fc1)\n",
    "model.add_layer(fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at epoch 100 is 0.6440368060776518\n",
      "Cost at epoch 200 is 0.675799682649059\n",
      "Cost at epoch 300 is 0.7455867313390562\n",
      "Cost at epoch 400 is 0.8362724763418984\n",
      "Cost at epoch 500 is 0.9388070133124284\n",
      "Cost at epoch 600 is 1.0485109483248025\n",
      "Cost at epoch 700 is 1.1628038737899724\n",
      "Cost at epoch 800 is 1.2801230532737273\n",
      "Cost at epoch 900 is 1.3994744751049797\n",
      "Cost at epoch 1000 is 1.5202072799615736\n",
      "Cost at epoch 1100 is 1.641886831562591\n",
      "Cost at epoch 1200 is 1.7642189243658075\n",
      "Cost at epoch 1300 is 1.887002533854245\n",
      "Cost at epoch 1400 is 2.0100994071920097\n",
      "Cost at epoch 1500 is 2.1334140309228915\n",
      "Cost at epoch 1600 is 2.256880210320694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-360-44769186aa94>:4: RuntimeWarning: overflow encountered in exp\n",
      "  A = 1.0/(1.0 + np.exp(-Z))  # Activation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at epoch 1700 is 2.3804519689161854\n",
      "Cost at epoch 1800 is 2.50409732420074\n",
      "Cost at epoch 1900 is 2.6277940044922112\n",
      "Cost at epoch 2000 is 2.751526488889438\n",
      "Cost at epoch 2100 is 2.8752839554175127\n",
      "Cost at epoch 2200 is 2.9990588556990474\n",
      "Cost at epoch 2300 is 3.122845923373247\n",
      "Cost at epoch 2400 is 3.2466414835501776\n"
     ]
    }
   ],
   "source": [
    "model.train(train_x, train_y, 2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.32501195 0.32501195 0.32501195 0.32501195 0.32501195 0.32501195\n",
      "  0.32501195 0.32501195 0.32501195 0.32501195 0.32501195 0.32501195\n",
      "  0.32501195 0.32501195 0.32501195 0.32501195 0.32501195 0.32501195\n",
      "  0.32501195 0.32501195 0.32501195 0.32501195 0.32501195 0.32501195\n",
      "  0.32501195 0.32501195 0.32501195 0.32501195 0.32501195 0.32501195]]\n"
     ]
    }
   ],
   "source": [
    "model.predict(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y=X\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit = FullyConnectedUnit(2,2,'Sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.62434536, -0.61175641, -0.52817175, -1.07296862,  0.86540763,\n",
       "        -2.3015387 ,  1.74481176, -0.7612069 ,  0.3190391 , -0.24937038,\n",
       "         1.46210794, -2.06014071, -0.3224172 , -0.38405435,  1.13376944,\n",
       "        -1.09989127, -0.17242821, -0.87785842,  0.04221375,  0.58281521,\n",
       "        -1.10061918,  1.14472371,  0.90159072,  0.50249434,  0.90085595,\n",
       "        -0.68372786, -0.12289023, -0.93576943, -0.26788808,  0.53035547]])"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "X = np.random.randn(1, 30)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "        1, 1, 1, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y=(X>0).astype(int)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1 = np.zeros((4,1))\n",
    "b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2 = np.array([[ 0]])\n",
    "b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00416758, -0.00056267],\n",
       "       [-0.02136196,  0.01640271],\n",
       "       [-0.01793436, -0.00841747],\n",
       "       [ 0.00502881, -0.01245288]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1 = np.array([[-0.00416758, -0.00056267],\n",
    "        [-0.02136196,  0.01640271],\n",
    "        [-0.01793436, -0.00841747],\n",
    "        [ 0.00502881, -0.01245288]])\n",
    "W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01057952, -0.00909008,  0.00551454,  0.02292208]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2 = np.array([[-0.01057952, -0.00909008,  0.00551454,  0.02292208]])\n",
    "W2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.62434536, -0.61175641, -0.52817175],\n",
       "       [-1.07296862,  0.86540763, -2.3015387 ]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit2 = FullyConnectedUnit(2,1,'Sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "(2, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.50115918, 0.50059516, 0.49369569],\n",
       "       [0.50024059, 0.49995443, 0.49966299]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A1, cache1 = unit.forward(X)\n",
    "A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "A2, cache2 = unit2.forward(A1)\n",
    "A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache[0] ## X,W,B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache[1] ## Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.array([[0],[1]])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy_cost()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Z = cache[0][1].dot(cache[0][0])\n",
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x(np.random.rand(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
